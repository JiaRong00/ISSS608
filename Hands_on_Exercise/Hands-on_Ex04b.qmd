---
title: "Hands-on Exercise 04b: Visual Statistical Analysis"
format:
  html:
    fontcolor: '#3b3b3b'
    code-line-numbers: true
author: "Moo Jia Rong"
date: "February 1, 2025"
date-modified: "last-modified"
execute:
  echo: true
  eval: true
  warning: false
  freeze: true 
---

### **1 Overview**

In this exercise, we will gain hands-on experience on using:

-   ggstatsplot package to create visual graphics with rich statistical information,
-   performance package to visualise model diagnostics, and
-   parameters package to visualise model parameters

### **2 Getting Started**

::: panel-tabset

## Loading Libraries
```{r}
pacman::p_load(ggstatsplot, tidyverse)
```

## Import dataset
```{r}
exam <- read_csv("data/Exam_data.csv")
exam
```
:::

### **3 Statistical Tests**

#### **3.1 One-sample test: gghistostats() method**

`ghistostats()` can be used to build an visual of one-sample test on English scores.

In addition, we can use `grouped_gghistostats()` to separate the tests by group.

::: panel-tabset

## non-grouped
```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)

gghistostats(
  data = exam,
  x = ENGLISH,
  type = "bayes",
  test.value = 60,
  xlab = "English scores"
)
```

## grouped
```{r}
#| code-fold: true
#| code-summary: "Show the code"
set.seed(1234)

grouped_gghistostats(
  data = exam,
  x = ENGLISH,
  type = "bayes",
  test.value = 60,
  xlab = "English scores",
  grouping.var      = GENDER
)
```

:::

#### **3.2 Bayes Factor**

-   A Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.

-   Thatâ€™s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.

-   When we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10.

#### **3.3 Two-sample mean test: ggbetweenstats()**

In the code chunk below, `ggbetweenstats()` is used to build a visual for two-sample mean test of Maths scores by gender.

We can change the colors by specifying `package` (package from which color palette is to be taken) and `palette`.

::: panel-tabset

## Default
```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggbetweenstats(
  data = exam,
  x = GENDER, 
  y = MATHS,
  type = "np",
  messages = FALSE
)
```

## Changing color palette
```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggbetweenstats(
  data = exam,
  x = GENDER, 
  y = MATHS,
  type = "np",
  messages = FALSE,
  package = "ggsci",
  palette = "nrc_npg"
)
```

:::

Apart from being able to change the color palattes,

-   The `type` (of test) argument also accepts the following abbreviations: "p" (for parametric), "np" (for nonparametric), "r" (for robust), "bf" (for Bayes Factor).

-   The type of plot to be displayed can also be modified ("box", "violin", or "boxviolin"). The default is boxviolin

::: panel-tabset

## Box
`violin.args` can be modified to remove the violin
```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggbetweenstats(
  data = exam,
  x = GENDER, 
  y = MATHS,
  type = "np",
  messages = FALSE,
  # to remove violin plot
  violin.args = list(width = 0)
)
```

## Violin
`boxplot.args` can be modified to remove the boxplot
```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggbetweenstats(
  data = exam,
  x = GENDER, 
  y = MATHS,
  type = "np",
  messages = FALSE,
  # to remove box plot
  boxplot.args = list(width = 0)
)
```

:::

#### **3.4 Oneway ANOVA Test: ggbetweenstats() method**

In the code chunk below, `ggbetweenstats()` is used to build a visual for One-way ANOVA test on English score by race.

-   `pairwise.display` has three options, 'ns': shows only non-signififcant, 's': shows only significant, 'all': displays all pairwise comparisons
-    `p.adjust.method` determines the method for adjusting p-values for multiple tests 

```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggbetweenstats(
  data = exam,
  x = RACE, 
  y = ENGLISH,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

#### **3.5 Significant Test of Correlation: ggscatterstats()**

In the code chunk below, `ggscatterstats()` is used to build a visual for Significant Test of Correlation between Maths scores and English scores.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggscatterstats(
  data = exam,
  x = MATHS,
  y = ENGLISH,
  marginal = FALSE,
  )
```

#### **3.6 Significant Test of Association (Depedence) : ggbarstats() methods**

In the code chunk below, the Maths scores is binned into a 4-class variable by using `cut()`.

```{r}
exam1 <- exam %>% 
  mutate(MATHS_bins = 
           cut(MATHS, 
               breaks = c(0,60,75,85,100))
)
```

In this code chunk below `ggbarstats()` is used to build a visual for Significant Test of Association

```{r}
ggbarstats(exam1, 
           x = MATHS_bins, 
           y = GENDER
           )
```

To change the display of percentages to include decimal points, we can modify the `digits.perc` argument

```{r}
ggbarstats(exam1, 
           x = MATHS_bins, 
           y = GENDER,
           digits.perc = 1)
```

### **4 Visualising Models**

In this section, we will visualise model diagnostic and model parameters by using parameters package.

The Toyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.

#### **4.1 Getting Started**

::: panel-tabset 

## Loading packages
```{r}
pacman::p_load(readxl, performance, parameters, see)
```

## Importing dataset
```{r}
car_resale <- read_xls("data/ToyotaCorolla.xls", 
                       "data")
car_resale
```

:::

#### **4.2 Multiple Regression Model using lm()**

The code chunk below is used to calibrate a multiple linear regression model by using `lm()` of Base Stats of R.

```{r}
model <- lm(Price ~ Age_08_04 + Mfg_Year + KM + 
              Weight + Guarantee_Period, data = car_resale)
model
```

#### **4.3 Model Diagnostic: checking for multicolinearity:**

In the code chunk below, `check_collinearity()` of performance package is used to check for multicolinearity of variables included in the regression model.

```{r}
check_collinearity(model)
```

```{r}
check_c <- check_collinearity(model)
plot(check_c)
```

#### **4.4 Model Diagnostic: checking normality assumption**

In the code chunk below, `check_normality()` of performance package is used to check for normality of the variables.

```{r}
model1 <- lm(Price ~ Age_08_04 + KM + 
              Weight + Guarantee_Period, data = car_resale)

check_n <- check_normality(model1)

plot(check_n)
```

#### **4.5 Model Diagnostic: Check model for homogeneity of variances**

In the code chunk below, `check_heteroscedasticity()` of performance package is used to check for homogeneity of variances.

```{r}
check_h <- check_heteroscedasticity(model1)

plot(check_h)
```

#### **4.6 Model Diagnostic: Complete check**

Alternatively, We can also perform all the checks at once by using `check_model()`.

```{r}
check_model(model1)
```


#### **4.7 Visualising Regression Parameters: see methods**

In the code below, `plot()` of see package and `parameters()` of parameters package is used to visualise the parameters of a regression model.

```{r}
plot(parameters(model1))
```

#### **4.8 Visualising Regression Parameters: ggcoefstats() methods**

In the code below, `ggcoefstats()` of ggstatsplot package to visualise the parameters of a regression model.

```{r}
ggcoefstats(model1, 
            output = "plot")
```
